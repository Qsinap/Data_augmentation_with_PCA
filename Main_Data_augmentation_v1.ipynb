{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Main_Data_augmentation_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDBVqYlPISkx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7MVcOQDEFI3"
      },
      "source": [
        "!pip install tensorflow-addons\n",
        "!pip install -q tensorflow-io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djHi7EIaIM3i"
      },
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import math\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import time\n",
        "import cv2\n",
        "import tensorflow_addons as tfa\n",
        "from skimage.transform import resize\n",
        "from IPython.display import clear_output\n",
        "import tensorflow_io as tfio"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTTzjJw0-4jd"
      },
      "source": [
        "def one_hot(vec):\n",
        "  items=np.sort(pd.unique(vec))\n",
        "  n_class=np.shape(items)[0]\n",
        "  zeros=np.zeros((vec.size, n_class))\n",
        "  for n,i in enumerate(items):\n",
        "    rows=np.where(vec==i)[0]\n",
        "    zeros[rows,n]=1\n",
        "  return zeros.astype('float32'), n_class"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY318_Utj095"
      },
      "source": [
        "def get_index(vec_lab, seed=1996, split_train=0.6, validation=False):\n",
        "  train=[]\n",
        "  valid=[]\n",
        "  test =[]\n",
        "\n",
        "  spv=(1-split_train)/2.\n",
        "  for i in range(2):\n",
        "    ind_clss=np.where(vec_lab[:,i]==1)[0]\n",
        "    sz=len(ind_clss)\n",
        "    np.random.seed(seed)\n",
        "    ramd=np.random.choice(sz, sz, replace=False)\n",
        "    train=np.append(train, ind_clss[ramd[:int(sz*split_train)]])\n",
        "    valid=np.append(valid, ind_clss[ramd[int(sz*split_train):int(sz*(split_train+spv))]])\n",
        "    test =np.append(test, ind_clss[ramd[int(sz*(split_train+spv)):]])\n",
        "  train=train[np.random.choice(len(train), len(train), replace=False)].astype('int')\n",
        "  valid=valid[np.random.choice(len(valid), len(valid), replace=False)].astype('int')\n",
        "  test= test[np.random.choice(len(test), len(test), replace=False)].astype('int')\n",
        "  if validation:\n",
        "    return train, valid, test\n",
        "  else:\n",
        "    return np.concatenate((train,valid)), test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pegh3eH01sO6"
      },
      "source": [
        "### Data augmentation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI1camqieOhr"
      },
      "source": [
        "def none_p(data, labx):\n",
        "  return data, labx"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmpBZebzsKRw"
      },
      "source": [
        "def aug_translation(data, labx):\n",
        "  sz=np.shape(data)\n",
        "  new=np.zeros((3,*sz))\n",
        "  tx=int(sz[1]/4)\n",
        "  ty=int(sz[2]/4)  \n",
        "  new[0,:,tx:,ty:,:]=data[:,:-tx,:-ty,:]\n",
        "  new[1,:,:,ty:,:]=data[:,:,:-ty,:]\n",
        "  new[2,:,tx:,:,:]=data[:,:-tx,:,:]\n",
        "  images=tf.concat([data,\n",
        "                    new[0],\n",
        "                    new[1],\n",
        "                    new[2]], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ebtAOwgECsw"
      },
      "source": [
        "def aug_rotation(data, labx):\n",
        "  images=tf.concat([data,\n",
        "                  tfa.image.rotate(data, angles=np.pi/2),\n",
        "                  tfa.image.rotate(data, angles=np.pi),\n",
        "                  tfa.image.rotate(data, angles=np.pi*3/2)], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2DmQR-RsvxQ"
      },
      "source": [
        "def aug_flip(data, labx):\n",
        "  images=tf.concat([data,\n",
        "                    tf.image.flip_left_right(data),\n",
        "                    tf.image.flip_up_down(data),\n",
        "                    tf.image.flip_up_down(tf.image.flip_left_right(data))], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-1-gvEZswfS"
      },
      "source": [
        "def aug_zoom(data, labx):\n",
        "  sz=np.shape(data)\n",
        "  new=np.zeros((3,*sz))\n",
        "  zoom=tf.image.resize(data, [int(sz[1]*3/4),int(sz[2]*3/4)])\n",
        "  new[0,:,int(sz[1]/8):int(sz[1]*7/8),int(sz[2]/8):int(sz[2]*7/8),:]=zoom\n",
        "  zoom=tf.image.resize(data, [int(sz[1]/2),int(sz[2]/2)])\n",
        "  new[1,:,int(sz[1]/4):int(sz[1]*3/4),int(sz[2]/4):int(sz[2]*3/4),:]=zoom\n",
        "  zoom=tf.image.resize(data, [int(sz[1]*3/2),int(sz[2]*3/2)])\n",
        "  new[2,...]=zoom[:,int(sz[1]/4):int(sz[1]*5/4),int(sz[2]/4):int(sz[2]*5/4),:]\n",
        "  images=tf.concat([data,\n",
        "                    new[0],\n",
        "                    new[1],\n",
        "                    new[2]], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVgj46b8LAqr"
      },
      "source": [
        "def distortion_ima(data, sx=1, sy=3/2, ang=45):\n",
        "  sz=np.shape(data)\n",
        "  new=tfa.image.rotate(data,np.pi*ang/180)\n",
        "  new=tf.image.resize(new, [int(sz[1]*sx),int(sz[2]*sy)])\n",
        "  new=tfa.image.rotate(new, -np.pi*ang/180)\n",
        "  szn=np.shape(new)\n",
        "  new=new[:,int(np.abs(szn[1]-sz[1])/2):int((np.abs(szn[1]-sz[1])/2)+sz[1]),int(np.abs(szn[2]-sz[2])/2):int((np.abs(szn[2]-sz[2])/2)+sz[2]),:]\n",
        "  return new"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL07oer-swbf"
      },
      "source": [
        "def aug_distortion(data, labx):\n",
        "  images=tf.concat([data,\n",
        "                    distortion_ima(data,1,3/2,45),\n",
        "                    distortion_ima(data,3/2,1,45),\n",
        "                    distortion_ima(data,3/2,1.1,120)], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJw0KxQ2E9G"
      },
      "source": [
        "def rx(ix):\n",
        "  r=np.random.choice(ix,ix,replace=False)\n",
        "  return r\n",
        "\n",
        "def aument(ind_0, tipo, aug=3):\n",
        "  sz0=np.shape(ind_0)\n",
        "  new0=np.zeros((aug,*sz0))\n",
        "\n",
        "  for j in range(aug):\n",
        "    new0[j,:,:int(sz0[1]/2),:int(sz0[2]/2),:]=ind_0[rx(sz0[0]),:int(sz0[1]/2),:int(sz0[2]/2),:]\n",
        "    new0[j,:,:int(sz0[1]/2),int(sz0[2]/2):,:]=ind_0[rx(sz0[0]),:int(sz0[1]/2),int(sz0[2]/2):,:]\n",
        "    new0[j,:,int(sz0[1]/2):,:int(sz0[2]/2),:]=ind_0[rx(sz0[0]),int(sz0[1]/2):,:int(sz0[2]/2),:]\n",
        "    new0[j,:,int(sz0[1]/2):,int(sz0[2]/2):,:]=ind_0[rx(sz0[0]),int(sz0[1]/2):,int(sz0[2]/2):,:]\n",
        "  \n",
        "  ys=np.ones(aug*sz0[0])*tipo\n",
        "  return new0, ys"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiZSVFXRswUY"
      },
      "source": [
        "def aug_cropping(data, labx):\n",
        "  ind_0=np.array(data)[np.where(labx[:,0]==1)[0],...]\n",
        "  ind_1=np.array(data)[np.where(labx[:,1]==1)[0],...]\n",
        "\n",
        "  new0, lab0=aument(ind_0, 0)\n",
        "  new1, lab1=aument(ind_1, 1)\n",
        "  lab_0,_=one_hot(np.concatenate((lab0,lab1)))\n",
        "\n",
        "  images=tf.concat([data, new0[0], new0[1], new0[2],\n",
        "                    new1[0], new1[1], new1[2]], 0)\n",
        "  lab=tf.concat([labx,lab_0], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnFMDYF399Wp"
      },
      "source": [
        "def sub_overlap(ind_0, tipo, aug=3):\n",
        "  sz0=np.shape(ind_0)\n",
        "  new0=np.zeros((aug,*sz0))\n",
        "\n",
        "  for j in range(aug):\n",
        "    new0[j]=ind_0[rx(sz0[0])]+ind_0[rx(sz0[0])]\n",
        "    new0[j]=tf.image.per_image_standardization(new0[j])\n",
        "    new0[j]=(new0[j]-np.min(new0[j]))/(np.max(new0[j])-np.min(new0[j]))  \n",
        "  ys=np.ones(aug*sz0[0])*tipo\n",
        "  return new0, ys"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RKdHwVs9Uy"
      },
      "source": [
        "def aug_overlap(data, labx):\n",
        "  ind_0=np.array(data)[np.where(labx[:,0]==1)[0],...]\n",
        "  ind_1=np.array(data)[np.where(labx[:,1]==1)[0],...]\n",
        "\n",
        "  new0, lab0=sub_overlap(ind_0, 0)\n",
        "  new1, lab1=sub_overlap(ind_1, 1)\n",
        "  lab_0,_=one_hot(np.concatenate((lab0,lab1)))\n",
        "\n",
        "  images=tf.concat([data, new0[0], new0[1], new0[2],\n",
        "                    new1[0], new1[1], new1[2]], 0)\n",
        "  lab=tf.concat([labx,lab_0], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsj5jus6s9Sf"
      },
      "source": [
        "def aug_add_noise(data, labx):\n",
        "  sz1=np.shape(data)\n",
        "  new=np.zeros((3,*sz1))\n",
        "  for i in range(3):\n",
        "    thres=0.05*(1+i)\n",
        "    black=np.random.rand(*sz1)>thres\n",
        "    white=np.random.rand(*sz1)<(1-thres)\n",
        "    new[i]=(data*black*white)+(1-white)\n",
        "  images=tf.concat([data, new[0], new[1], new[2]], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLA6afyKs9P3"
      },
      "source": [
        "def aug_color_space(data, labx):\n",
        "  space1=tfio.experimental.color.rgb_to_ycbcr(np.array(data*255/np.max(data)).astype('uint8'))\n",
        "  space2=tfio.experimental.color.rgb_to_hsv((np.array(space1)/np.max(space1)).astype('float32'))\n",
        "  space3=tfio.experimental.color.xyz_to_rgb(space2)\n",
        "  space1=np.array(space1).astype('float32')\n",
        "  space1=(space1-np.min(space1))/(np.max(space1)-np.min(space1))\n",
        "  images=tf.concat([data, space1, space2, space3], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIBJLFFFtIou"
      },
      "source": [
        "def aug_linear_kernel(data, labx):\n",
        "  images=tf.concat([data,\n",
        "                    tfa.image.gaussian_filter2d(data, (3,3), sigma=7),\n",
        "                    tfa.image.gaussian_filter2d(data, (4,4), sigma=7),\n",
        "                    tfa.image.gaussian_filter2d(data, (5,5), sigma=7)], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YDkanP8cxES"
      },
      "source": [
        "def delete_box(data):\n",
        "  sz1=np.shape(data)\n",
        "  uno=np.zeros(sz1)\n",
        "  xp=(np.random.rand(sz1[0])*sz1[1]).astype('int')\n",
        "  yp=(np.random.rand(sz1[0])*sz1[2]).astype('int')\n",
        "  uno[np.arange(sz1[0]),xp,yp,:]=1\n",
        "  uno=tf.nn.dilation2d(uno, np.ones((int(sz1[1]/3),int(sz1[2]/3),3)), [1,1,1,1], 'SAME', 'NHWC', [1,1,1,1])\n",
        "  uno=np.array(uno!=np.max(uno))\n",
        "  new=data*uno\n",
        "  return new"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUnzQ37ptJGy"
      },
      "source": [
        "def aug_random_delete(data, labx):\n",
        "  images=tf.concat([data,\n",
        "                    delete_box(data),\n",
        "                    delete_box(data),\n",
        "                    delete_box(data)], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT0eRwC0fGiR"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldLMKIgjgFin"
      },
      "source": [
        "def noise(x,y,per=0.1):\n",
        "  rand=np.random.rand(x,y)\n",
        "  frac=(per)/(np.max(rand)-per)\n",
        "  rand2=rand+frac\n",
        "  rand2=rand2/np.max(rand2)\n",
        "  return rand2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzsFizcoAvON"
      },
      "source": [
        "def pca_images(data, percentage=0.1):\n",
        "  sz1=np.shape(data)\n",
        "  flat=np.array(data[...,0]).reshape(sz1[0],sz1[1]*sz1[2])\n",
        "  ncomp=np.min(np.shape(flat))\n",
        "  pca = PCA(n_components=ncomp)\n",
        "  pca.fit(flat)\n",
        "  space1=pca.transform(flat)\n",
        "  x,y=np.shape(space1)\n",
        "  new=np.zeros((3,*sz1))\n",
        "  for i in range(3):\n",
        "    for j in range(3):\n",
        "      rand=noise(x,y,percentage)\n",
        "      ima=space1*rand\n",
        "      ima=pca.inverse_transform(ima)\n",
        "      ima=(ima-np.min(ima))/(np.max(ima)-np.min(ima)).astype('float32')\n",
        "      ima=ima.reshape(sz1[0],sz1[1],sz1[2])\n",
        "      new[i,:,:,:,j]=ima\n",
        "  return new"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76O-XoH7tSog"
      },
      "source": [
        "def aug_PCA(data, labx):\n",
        "  new=pca_images(data)\n",
        "  images=tf.concat([data, new[0], new[1], new[2]], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQbWXR4Ddv_x"
      },
      "source": [
        "method={'None': none_p,\n",
        "        'Translation'\t: aug_translation,\n",
        "        'Rotation' : aug_rotation,\n",
        "        'Flip' : aug_flip,\n",
        "        'Resizing' : aug_zoom,\n",
        "        'Distortion' : aug_distortion,\n",
        "        'Cropping' : aug_cropping,\n",
        "        'Overlapping' : aug_overlap,\n",
        "        'Noise addition' : aug_add_noise,\n",
        "        'Change of color space' : aug_color_space,\n",
        "        'Linear filters' : aug_linear_kernel,\n",
        "        'Random frame deletion' : aug_random_delete,\n",
        "        'Based on PCA' : aug_PCA}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9fGugIcEwkA"
      },
      "source": [
        "def get_data_training(indx, ima_tens, labels_v, k_fold='none', number_folds=10, augm='None'):\n",
        "  if k_fold!='none':\n",
        "    sz=len(indx)/number_folds\n",
        "    valid=indx[int(k_fold*sz):int((k_fold+1)*sz)]\n",
        "    train=np.concatenate((indx[:int(k_fold*sz)],indx[int((k_fold+1)*sz):])) \n",
        "\n",
        "    x_data=tf.image.grayscale_to_rgb(tf.convert_to_tensor(np.array(ima_tens)[train]))\n",
        "    v_data=tf.image.grayscale_to_rgb(tf.convert_to_tensor(np.array(ima_tens)[valid]))\n",
        "    y_data=tf.convert_to_tensor(np.array(labels_v)[train])\n",
        "    vy_dat=tf.convert_to_tensor(np.array(labels_v)[valid])\n",
        "\n",
        "    x_data, y_data=method[augm](x_data, y_data)\n",
        "    v_data, vy_dat=method[augm](v_data, vy_dat)\n",
        "\n",
        "    return x_data, v_data, y_data, vy_dat\n",
        "  else:\n",
        "    x_data=tf.image.grayscale_to_rgb(tf.convert_to_tensor(np.array(ima_tens)[indx]))\n",
        "    y_data=tf.convert_to_tensor(np.array(labels_v)[indx])\n",
        "\n",
        "    x_data, y_data=method[augm](x_data, y_data)\n",
        "\n",
        "    return x_data, y_data"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SizDSRhbrmEQ"
      },
      "source": [
        "def reduce_data(labels, reduction=100):\n",
        "  sub, clas=np.shape(labels)\n",
        "  new_labels=[]\n",
        "  for i in range(clas):\n",
        "    i_tem=np.where(labels[:,i]==1)[0]\n",
        "    rand=np.random.choice(np.shape(i_tem)[0], np.shape(i_tem)[0], replace=False)[:reduction]\n",
        "    new_labels=np.append(new_labels,i_tem[rand])\n",
        "  return new_labels.astype('int')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCy_IAjDgO5z"
      },
      "source": [
        "def get_data(sequences='T1'): #'FLAIR','T1_Gd'\n",
        "  data_dir=('/content/drive/MyDrive/Brain_tumors_v2/Datasets/TCIA_LGG/x_x.mat')\n",
        "  mats=sio.loadmat(data_dir.replace('x_x', sequences))\n",
        "  images=mats['images']\n",
        "  tumors=mats['size_tumor'][0]\n",
        "\n",
        "  choise=np.argsort(np.var(np.var(images, axis=1), axis=1))[900:]\n",
        "  images=images[choise]\n",
        "  tumors=tumors[choise]\n",
        "\n",
        "  images=images.reshape((np.shape(images)[0],np.shape(images)[1],np.shape(images)[2],1))\n",
        "  labels=(tumors!=0).astype('int') #para TCIA tres canales pero la misma mascara\n",
        "  images=tf.image.resize(images, [100,100], method='nearest')\n",
        "  labels, n_class=one_hot(labels)\n",
        "  indx=reduce_data(labels)\n",
        "  return tf.convert_to_tensor(np.array(images)[indx]), labels[indx], n_class"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRZKTokAW-X"
      },
      "source": [
        "from tensorflow.keras import applications as ap\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_h7Ln2LyCOM"
      },
      "source": [
        "def get_model(network, opt='adadelta', loss_name='categorical_crossentropy', input_shape=(240,240,3), classes=2, weights='imagenet'):\n",
        "  try:\n",
        "    del model\n",
        "  except:\n",
        "    print('done')\n",
        "  model=Sequential()\n",
        "  if network=='ResNet50V2':\n",
        "    model.add(ap.ResNet50V2(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) # The input must have 3 channels\n",
        "  if network=='EfficientNetB7':\n",
        "    model.add(ap.EfficientNetB7(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='InceptionResNetV2':\n",
        "    model.add(ap.InceptionResNetV2(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='InceptionV3':\n",
        "    model.add(ap.InceptionV3(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='NASNetLarge':\n",
        "    model.add(ap.NASNetLarge(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes))\n",
        "  if network=='VGG19':\n",
        "    model.add(ap.VGG19(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='Xception':\n",
        "    model.add(ap.Xception(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes))\n",
        "  if network=='DenseNet121':\n",
        "    model.add(ap.DenseNet121(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes))\n",
        "  \n",
        "  model.add(Dense(classes, activation='softmax'))\n",
        "  model.compile(optimizer=opt, loss=loss_name, metrics=['acc', tf.keras.metrics.Recall(), tf.keras.metrics.FalsePositives()])\n",
        "  return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "6DoCiB1QEEb-",
        "outputId": "0d2b353d-dd14-41b9-9b5b-7a3ff3b3b93f"
      },
      "source": [
        "df = pd.DataFrame(columns=('run_n', 'k_fold', 'network', 'optimizer', 'loss', 'epochs', 'total_parameters', 'time', 'transfer', 'augm', 'Class', 'TP', 'TN', 'FP', 'FN','result_mat'))\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_n</th>\n",
              "      <th>k_fold</th>\n",
              "      <th>network</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>loss</th>\n",
              "      <th>epochs</th>\n",
              "      <th>total_parameters</th>\n",
              "      <th>time</th>\n",
              "      <th>transfer</th>\n",
              "      <th>augm</th>\n",
              "      <th>Class</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>result_mat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [run_n, k_fold, network, optimizer, loss, epochs, total_parameters, time, transfer, augm, Class, TP, TN, FP, FN, result_mat]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4sq7omoAW45"
      },
      "source": [
        "TP=tf.keras.metrics.TruePositives()\n",
        "TN=tf.keras.metrics.TrueNegatives()\n",
        "FP=tf.keras.metrics.FalsePositives()\n",
        "FN=tf.keras.metrics.FalseNegatives()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elarYVjSCxnf"
      },
      "source": [
        "def run_experiment(images, labels, number_class, augm_method, name='', star_run=0, end_run=30, batch_size=4):\n",
        "  for augm_con in augm_method: \n",
        "    for net in Networks:\n",
        "      name_0='_'.join(['Augmentation', name, str(transferlearning), augm_con, net, optimizer])\n",
        "      if not os.path.exists(path2+name_0+'.csv'):\n",
        "        df.to_csv(path2+name_0+'.csv')\n",
        "\n",
        "      train_id, test_id=get_index(labels)\n",
        "      x_test, y_test=get_data_training(test_id, images, labels)\n",
        "      y_test=y_test>=0.5\n",
        "\n",
        "      for i in range(star_run, end_run): #Numero corridas \n",
        "        for j in [loss]: #Funciones de perdida\n",
        "          cntn=True\n",
        "          name_m='_'.join([name_0,j,'run',str(i)])  \n",
        "          print(name_m)\n",
        "\n",
        "          #Obtener imagenes nuevamente\n",
        "          x_train, x_valid, y_train, y_valid=get_data_training(train_id, images, labels, k_fold=i%10, augm=augm_con)      \n",
        "          model=get_model(net, classes=number_class, input_shape=list(np.shape(x_train)[1:]),  weights=transferlearning)\n",
        "          \n",
        "          try:\n",
        "            tic = time.time()\n",
        "            results = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=batch_size, epochs=epochs)\n",
        "            toc=time.time()-tic\n",
        "            model.save_weights(pathW+name_m+\"w.h5\")\n",
        "          except:\n",
        "            print('Training error')\n",
        "            cntn=False\n",
        "\n",
        "          if cntn:\n",
        "            sio.savemat(pathW+name_m+'_r.mat', results.history)\n",
        "\n",
        "            #Validation\n",
        "            y_hat=np.array(model.predict(x_test))\n",
        "            sio.savemat(pathW+name_m+'_los_8.mat',{'y_hat': y_hat, 'y_test': np.array(y_test)})\n",
        "            y_hat=y_hat>=0.5\n",
        "\n",
        "            for class_i in range(number_class):\n",
        "              TP.reset_state()\n",
        "              TN.reset_state()\n",
        "              FP.reset_state()\n",
        "              FN.reset_state()        \n",
        "\n",
        "              TP.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "              TN.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "              FP.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "              FN.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "              total_p=model.count_params()\n",
        "\n",
        "              #data frame\n",
        "              df2=pd.read_csv(path2+name_0+'.csv')\n",
        "              df2=df2.append({'run_n': i,\n",
        "                              'k_fold': i%10,\n",
        "                              'network': net,\n",
        "                              'optimizer': optimizer,\n",
        "                              'loss': 'categorical_crossentropy',\n",
        "                              'epochs': epochs,\n",
        "                              'total_parameters': total_p,\n",
        "                              'time': toc,\n",
        "                              'transfer': transferlearning,\n",
        "                              'augm': augm_con,\n",
        "                              'Class': class_i,\n",
        "                              'TP': float(TP.result()),\n",
        "                              'TN': float(TN.result()),\n",
        "                              'FP': float(FP.result()),\n",
        "                              'FN': float(FN.result()),\n",
        "                              'result_mat': name_m+'_r.mat'} , ignore_index=True)\n",
        "              df2=df2.drop(df2.columns[:np.where(df2.columns=='run_n')[0][0]], axis=1)\n",
        "              df2.to_csv(path2+name_0+'.csv')\n",
        "            del x_train, y_train, x_valid, y_valid, model\n",
        "            clear_output(wait=True)\n",
        "      star_run=0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQrrA6JqKeSz"
      },
      "source": [
        "# Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60hh25h9AW7g"
      },
      "source": [
        "Networks=['ResNet50V2', 'EfficientNetB7', 'InceptionResNetV2', 'InceptionV3', 'VGG19', 'Xception', 'DenseNet121']\n",
        "path2='/content/drive/MyDrive/Brain_tumors_v2/Results/AumentoDeDatos/ceros/results_csv/'\n",
        "pathW='/content/drive/MyDrive/Brain_tumors_v2/Results/AumentoDeDatos/ceros/Weights/'\n",
        "transferlearning=None\n",
        "optimizer='adadelta'\n",
        "epochs=50\n",
        "loss='categorical_crossentropy'\n",
        "augmentation=['None', 'Translation', 'Rotation', 'Flip', 'Resizing', 'Distortion', 'Cropping', 'Overlapping', 'Noise addition', 'Change of color space', 'Linear filters', 'Random frame deletion', 'Based on PCA']\n",
        "\n",
        "\n",
        "#----------------------------------RUN------------------------------------------\n",
        "seq='FLAIR'#,'T1_Gd'\n",
        "imas, labs, no_cls=get_data(seq)\n",
        "run_experiment(imas, labs, no_cls, augmentation, seq, star_run=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}